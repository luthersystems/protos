syntax = "proto3";

package connectors.v1;

import "annotations/v1/sensitive.proto";
import "grpc/gateway/protoc_gen_openapiv2/options/annotations.proto";

option go_package = "buf.build/gen/go/luthersystems/protos/protocolbuffers/go/connectors/v1";

// Connects to Hugging Face's Inference API, allowing access to pre-trained AI models for NLP, computer vision, and more.
message HuggingFaceInferenceConfig {
  option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_schema) = {
    json_schema: {
      title: "Hugging Face Inference"
      description: "Connects to Hugging Face's Inference API, allowing access to pre-trained AI models for NLP, computer vision, and more.\n@category: AI"
    }
  };

  string api_key = 1 [(annotations.v1.sensitive) = true];      // API key for authenticating with the Hugging Face Inference API
  string model_id = 2;                                         // ID of the model to use (e.g., bert-base-uncased)
  string api_endpoint = 3;                                     // Optional: custom API endpoint (defaults to https://api-inference.huggingface.co)
  int32 request_timeout = 4;                                   // Timeout for API requests, in seconds
}
